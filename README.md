# Robust Deep Monte Carlo Counterfactual Regret Minimization : Addressing Theoretical Risks in Neural Fictitious Self-Play

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)

A PyTorch implementation of Monte Carlo Counterfactual Regret Minimization (MCCFR) with deep neural networks for learning optimal strategies in imperfect information games.

## üéØ Overview

This library implements state-of-the-art algorithms for solving imperfect information games using deep learning. It combines the theoretical foundations of Counterfactual Regret Minimization (CFR) with modern deep learning techniques to learn near-optimal strategies in complex game environments.

### Key Features

- **Multiple Neural Network Architectures**: From simple feedforward networks to advanced transformer-based architectures
- **Robust Training**: Includes importance weight clipping, target networks, and variance reduction techniques
- **Comprehensive Evaluation**: Built-in exploitability calculation and strategy analysis tools
- **Modular Design**: Easy to extend to new games and network architectures
- **Research-Ready**: Includes experimental frameworks and diagnostic tools

### Supported Games

- **Kuhn Poker**: A simplified poker variant perfect for testing and research
- **Extensible Framework**: Easy to add new imperfect information games

## üöÄ Quick Start

### Installation

#### From Source (Recommended)

```bash
git clone https://github.com/your-username/robust-deep-mccfr.git
cd robust-deep-mccfr
pip install -e .
```
### Basic Usage

```python
from deep_mccfr import DeepMCCFR, KuhnGame

# Initialize the algorithm
mccfr = DeepMCCFR(
    network_type='ultra_deep',
    learning_rate=0.00003,
    batch_size=384
)

# Train on Kuhn Poker
results = mccfr.train(num_iterations=10000)

print(f"Final exploitability: {results['final_exploitability']:.6f}")
print(f"Training time: {results['training_time']:.1f}s")
```

### Advanced Usage with Robust Features

```python
from deep_mccfr import RobustDeepMCCFR, RobustMCCFRConfig

# Configure robust training
config = RobustMCCFRConfig(
    network_type='mega_transformer',
    exploration_epsilon=0.1,
    importance_weight_clip=10.0,
    use_target_networks=True,
    prioritized_replay=True,
    num_iterations=20000
)

# Initialize robust MCCFR
robust_mccfr = RobustDeepMCCFR(config)

# Train with advanced features
results = robust_mccfr.train(config.num_iterations)
```

## üèóÔ∏è Architecture

### Neural Network Architectures

The library includes several neural network architectures optimized for strategy learning:

1. **BaseNN**: Simple feedforward network with dropout
2. **DeepResidualNN**: Deep residual network with skip connections
3. **FeatureAttentionNN**: Self-attention mechanism for feature interactions
4. **HybridAdvancedNN**: Combines attention and residual processing
5. **MegaTransformerNN**: Large-scale transformer architecture
6. **UltraDeepNN**: Ultra-deep network with bottleneck residual blocks

### Key Components

- **Feature Extraction**: Sophisticated state representation for game states
- **Experience Replay**: Prioritized sampling for stable learning
- **Risk Mitigation**: Multiple techniques to ensure robust training
- **Diagnostic Tools**: Comprehensive monitoring and analysis

## üìä Experimental Results

The library includes extensive experimental frameworks for comparing different approaches:

```python
from deep_mccfr.experiments import ExperimentRunner, get_ablation_configs

# Run systematic ablation study
runner = ExperimentRunner()
configs = get_ablation_configs()

for config in configs:
    results = runner.run_experiment(config)
    
# Analyze results
runner.analyze_results()
```

### Performance Benchmarks

| Architecture | Parameters | Final Exploitability | Training Time |
|-------------|------------|---------------------|---------------|
| BaseNN | 0.5M | 0.001234 | 120s |
| DeepResidualNN | 2.1M | 0.000876 | 180s |
| UltraDeepNN | 8.4M | 0.000654 | 300s |
| MegaTransformerNN | 15.2M | 0.000543 | 450s |

*Results on Kuhn Poker with 10,000 training iterations*

## üî¨ Research Applications

This library has been used for research in:

- **Game Theory**: Analyzing equilibrium strategies in imperfect information games
- **Deep Learning**: Investigating neural network architectures for sequential decision making
- **Multi-Agent Systems**: Studying learning dynamics in competitive environments

### Citation

If you use this library in your research, please cite:

```bibtex
@software{eljaafari2024dlmccfr,
  author = {El-Jaafari, Zakaria},
  title = {Deep Learning Monte Carlo Counterfactual Regret Minimization},
  url = {https://github.com/your-username/robust-deep-mccfr},
  version = {1.0.0},
  year = {2024}
}
```

## üõ†Ô∏è Development

### Setting up Development Environment

```bash
# Clone the repository
git clone https://github.com/your-username/robust-deep-mccfr.git
cd robust-deep-mccfr

# Install development dependencies
pip install -e ".[dev]"

# Run tests
pytest tests/

# Format code
black src/

# Type checking
mypy src/
```

### Project Structure

```
robust-deep-mccfr/
‚îú‚îÄ‚îÄ src/robust-deep-mccfr/          # Main package
‚îÇ   ‚îú‚îÄ‚îÄ games/             # Game implementations
‚îÇ   ‚îú‚îÄ‚îÄ networks.py        # Neural network architectures
‚îÇ   ‚îú‚îÄ‚îÄ mccfr.py          # Core MCCFR algorithms
‚îÇ   ‚îú‚îÄ‚îÄ features.py       # Feature extraction
‚îÇ   ‚îú‚îÄ‚îÄ utils.py          # Utility functions
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py       # Package initialization
‚îú‚îÄ‚îÄ examples/             # Example scripts
‚îú‚îÄ‚îÄ tests/               # Unit tests
‚îú‚îÄ‚îÄ docs/                # Documentation
‚îú‚îÄ‚îÄ requirements.txt     # Dependencies
‚îú‚îÄ‚îÄ setup.py            # Package setup
‚îî‚îÄ‚îÄ README.md           # This file
```

### Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Ensure all tests pass
5. Submit a pull request

## üìö Documentation

### API Reference

Complete API documentation is available at [https://dl-mccfr.readthedocs.io/](https://dl-mccfr.readthedocs.io/)

### Tutorials

- [Getting Started with Kuhn Poker](docs/tutorials/kuhn_poker.md)
- [Neural Network Architectures Guide](docs/tutorials/networks.md)
- [Advanced Training Techniques](docs/tutorials/advanced_training.md)
- [Adding New Games](docs/tutorials/custom_games.md)

### Examples

Check the `examples/` directory for:

- **Basic Training**: Simple MCCFR training loop
- **Architecture Comparison**: Comparing different neural networks
- **Ablation Studies**: Systematic feature analysis
- **Custom Games**: How to implement new games

## üîß Configuration

### Network Types

```python
# Available network architectures
NETWORK_TYPES = [
    'simple',           # Basic feedforward
    'deep_residual',    # Deep residual network
    'feature_attention', # Attention-based
    'hybrid_advanced',  # Hybrid architecture
    'mega_transformer', # Large transformer
    'ultra_deep'        # Ultra-deep network
]
```

### Training Parameters

```python
# Common training configurations
CONFIGS = {
    'fast': {
        'batch_size': 128,
        'learning_rate': 0.001,
        'train_every': 50
    },
    'stable': {
        'batch_size': 384,
        'learning_rate': 0.00003,
        'train_every': 25
    },
    'research': {
        'batch_size': 512,
        'learning_rate': 0.00001,
        'train_every': 10
    }
}
```

## üêõ Troubleshooting

### Common Issues

1. **CUDA Out of Memory**: Reduce batch size or use a smaller network
2. **Slow Training**: Enable GPU acceleration or use simpler architectures
3. **Numerical Instability**: Adjust learning rate or enable gradient clipping

### Performance Optimization

- Use GPU acceleration for large networks
- Adjust batch size based on available memory
- Use mixed precision training for faster computation
- Enable experience replay for sample efficiency

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- Original MCCFR algorithm by Lanctot et al.
- Deep CFR extensions by Brown et al.
- PyTorch team for the excellent deep learning framework
- Game theory research community

## üìû Contact

- **Author**: Zakaria El Jaafari
- **Email**: [zakariaeljaafari0@gmail.com]
- **GitHub**: [https://github.com/nier2kirito](https://github.com/nier2kirito)

---

‚≠ê If you find this project helpful, please consider giving it a star on GitHub!
